{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c39cd6eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   CustomerID    200 non-null    object\n",
      " 1   CustomerName  200 non-null    object\n",
      " 2   Region        200 non-null    object\n",
      " 3   SignupDate    200 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 6.4+ KB\n",
      "None\n",
      "\n",
      "Sample Data:\n",
      "  CustomerID        CustomerName         Region  SignupDate\n",
      "0      C0001    Lawrence Carroll  South America  2022-07-10\n",
      "1      C0002      Elizabeth Lutz           Asia  2022-02-13\n",
      "2      C0003      Michael Rivera  South America  2024-03-07\n",
      "3      C0004  Kathleen Rodriguez  South America  2022-10-09\n",
      "4      C0005         Laura Weber           Asia  2022-08-15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"Customers.csv\"  # Replace with your actual path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Overview:\")\n",
    "print(data.info())\n",
    "print(\"\\nSample Data:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e57d06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No numerical columns found for scaling.\n",
      "Preprocessed Data Sample:\n",
      "   CustomerID  CustomerName  Region  SignupDate\n",
      "0           0           119       3          34\n",
      "1           1            54       0           3\n",
      "2           2           137       3         127\n",
      "3           3           103       3          46\n",
      "4           4           116       0          36\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Step 1: Handle missing values\n",
    "data.fillna(data.mean(numeric_only=True), inplace=True)  # For numerical columns\n",
    "data.fillna(\"Unknown\", inplace=True)  # For categorical columns\n",
    "\n",
    "# Step 2: Encode categorical variables\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    data[col] = label_encoders[col].fit_transform(data[col])\n",
    "\n",
    "# Step 3: Scale numerical variables\n",
    "numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Check if `numerical_cols` contains valid columns\n",
    "if not numerical_cols.empty:\n",
    "    scaler = StandardScaler()\n",
    "    data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
    "else:\n",
    "    print(\"No numerical columns found for scaling.\")\n",
    "\n",
    "# Display the processed data\n",
    "print(\"Preprocessed Data Sample:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cacccb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No numerical columns found for scaling.\n",
      "Preprocessed Data Sample:\n",
      "   CustomerID  CustomerName  Region  SignupDate\n",
      "0           0           119       3          34\n",
      "1           1            54       0           3\n",
      "2           2           137       3         127\n",
      "3           3           103       3          46\n",
      "4           4           116       0          36\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Step 1: Handle missing values\n",
    "data.fillna(data.mean(numeric_only=True), inplace=True)  # For numerical columns\n",
    "data.fillna(\"Unknown\", inplace=True)  # For categorical columns\n",
    "\n",
    "# Step 2: Convert SignupDate to a numeric feature (if it's a date)\n",
    "# Assuming 'SignupDate' is the number of days since signup, so convert it to numeric\n",
    "if 'SignupDate' in data.columns:\n",
    "    data['SignupDate'] = pd.to_numeric(data['SignupDate'], errors='coerce')\n",
    "\n",
    "# Step 3: Encode categorical variables\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    data[col] = label_encoders[col].fit_transform(data[col])\n",
    "\n",
    "# Step 4: Scale numerical variables (excluding CustomerID and CustomerName)\n",
    "numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Exclude 'CustomerID' and 'CustomerName' if they are present\n",
    "numerical_cols = [col for col in numerical_cols if col not in ['CustomerID', 'CustomerName']]\n",
    "\n",
    "# Scale the remaining numerical columns\n",
    "if numerical_cols:\n",
    "    scaler = StandardScaler()\n",
    "    data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
    "else:\n",
    "    print(\"No numerical columns found for scaling.\")\n",
    "\n",
    "# Display the processed data\n",
    "print(\"Preprocessed Data Sample:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96ff1a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types of Columns:\n",
      "CustomerID      int32\n",
      "CustomerName    int32\n",
      "Region          int32\n",
      "SignupDate      int32\n",
      "dtype: object\n",
      "Data Types of Columns After Conversion:\n",
      "CustomerID      int32\n",
      "CustomerName    int32\n",
      "Region          int32\n",
      "SignupDate      int32\n",
      "dtype: object\n",
      "No numerical columns found for scaling.\n",
      "Preprocessed Data Sample:\n",
      "   CustomerID  CustomerName  Region  SignupDate\n",
      "0           0           119       3          34\n",
      "1           1            54       0           3\n",
      "2           2           137       3         127\n",
      "3           3           103       3          46\n",
      "4           4           116       0          36\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Print data types of all columns to check if they're correctly recognized\n",
    "print(\"Data Types of Columns:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Step 2: Convert 'Region' and 'SignupDate' to numeric if they are not already\n",
    "data['Region'] = pd.to_numeric(data['Region'], errors='coerce')  # Force conversion to numeric\n",
    "data['SignupDate'] = pd.to_numeric(data['SignupDate'], errors='coerce')  # Force conversion to numeric\n",
    "\n",
    "# Step 3: Handle missing values (since we forced conversion to numeric, some values might have become NaN)\n",
    "data.fillna(data.mean(numeric_only=True), inplace=True)  # For numerical columns\n",
    "data.fillna(\"Unknown\", inplace=True)  # For categorical columns\n",
    "\n",
    "# Step 4: Re-check the data types after conversion\n",
    "print(\"Data Types of Columns After Conversion:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Step 5: Encode categorical variables (if any)\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    data[col] = label_encoders[col].fit_transform(data[col])\n",
    "\n",
    "# Step 6: Identify numerical columns and scale them\n",
    "numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Exclude 'CustomerID' and 'CustomerName' if they are present\n",
    "numerical_cols = [col for col in numerical_cols if col not in ['CustomerID', 'CustomerName']]\n",
    "\n",
    "# Scale the remaining numerical columns\n",
    "if numerical_cols:\n",
    "    scaler = StandardScaler()\n",
    "    data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
    "else:\n",
    "    print(\"No numerical columns found for scaling.\")\n",
    "\n",
    "# Display the processed data\n",
    "print(\"Preprocessed Data Sample:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6657adc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types of Columns:\n",
      "CustomerID        int32\n",
      "CustomerName      int32\n",
      "Region          float64\n",
      "SignupDate      float64\n",
      "dtype: object\n",
      "Data Types of Columns After Conversion:\n",
      "CustomerID        int32\n",
      "CustomerName      int32\n",
      "Region          float64\n",
      "SignupDate      float64\n",
      "dtype: object\n",
      "Preprocessed Data Sample:\n",
      "   CustomerID  CustomerName    Region  SignupDate\n",
      "0           0           119  1.241384   -1.062450\n",
      "1           1            54 -1.409258   -1.647769\n",
      "2           2           137  1.241384    0.693509\n",
      "3           3           103  1.241384   -0.835874\n",
      "4           4           116 -1.409258   -1.024687\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Print data types of all columns to check if they're correctly recognized\n",
    "print(\"Data Types of Columns:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Step 2: Convert 'Region' and 'SignupDate' to numeric if they are not already\n",
    "data['Region'] = pd.to_numeric(data['Region'], errors='coerce')  # Force conversion to numeric\n",
    "data['SignupDate'] = pd.to_numeric(data['SignupDate'], errors='coerce')  # Force conversion to numeric\n",
    "\n",
    "# Step 3: Handle missing values (since we forced conversion to numeric, some values might have become NaN)\n",
    "data.fillna(data.mean(numeric_only=True), inplace=True)  # For numerical columns\n",
    "data.fillna(\"Unknown\", inplace=True)  # For categorical columns\n",
    "\n",
    "# Step 4: Re-check the data types after conversion\n",
    "print(\"Data Types of Columns After Conversion:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Step 5: Encode categorical variables (if any)\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    label_encoders[col] = LabelEncoder()\n",
    "    data[col] = label_encoders[col].fit_transform(data[col])\n",
    "\n",
    "# Step 6: Identify numerical columns explicitly and scale them\n",
    "# Include 'Region' and 'SignupDate' as numerical columns for scaling\n",
    "numerical_cols = ['Region', 'SignupDate']\n",
    "\n",
    "# Scale the numerical columns\n",
    "if numerical_cols:\n",
    "    scaler = StandardScaler()\n",
    "    data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
    "else:\n",
    "    print(\"No numerical columns found for scaling.\")\n",
    "\n",
    "# Display the processed data\n",
    "print(\"Preprocessed Data Sample:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65221dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations:\n",
      "   CustomerID  LookalikeCustomerID  SimilarityScore\n",
      "0         101                    0         1.000000\n",
      "1         101                    3         0.999738\n",
      "2         101                    2         0.997928\n",
      "\n",
      "CSV file 'Lookalike_Recommendations.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Example customer data (Region and SignupDate)\n",
    "df_customers = pd.DataFrame({\n",
    "    'CustomerID': [0, 1, 2, 3, 4],\n",
    "    'CustomerName': [119, 54, 137, 103, 116],\n",
    "    'Region': [3, 0, 3, 3, 0],\n",
    "    'SignupDate': [34, 3, 127, 46, 36]\n",
    "})\n",
    "\n",
    "# Function to calculate similarity (using Region and SignupDate)\n",
    "def calculate_similarity(user_data, customer_profiles):\n",
    "    similarity_scores = cosine_similarity([user_data], customer_profiles)\n",
    "    return similarity_scores.flatten()\n",
    "\n",
    "# Function to recommend lookalikes based on similarity\n",
    "def recommend_lookalikes(user_input, df_customers):\n",
    "    # Extract relevant customer profile columns (Region and SignupDate)\n",
    "    customer_profiles = df_customers[['Region', 'SignupDate']]\n",
    "    \n",
    "    # Calculate similarity scores\n",
    "    similarity_scores = calculate_similarity(user_input['TransactionData'], customer_profiles)\n",
    "    \n",
    "    # Get top 3 most similar customers\n",
    "    top_lookalikes = similarity_scores.argsort()[-3:][::-1]\n",
    "    recommendations = [\n",
    "        {'CustomerID': user_input['CustomerID'], \n",
    "         'LookalikeCustomerID': df_customers.iloc[i]['CustomerID'], \n",
    "         'SimilarityScore': similarity_scores[i]} \n",
    "        for i in top_lookalikes\n",
    "    ]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example user input (make sure 'TransactionData' matches the format: Region and SignupDate)\n",
    "user_input = {'CustomerID': 101, 'TransactionData': [3, 34]}  # Example Region=3, SignupDate=34\n",
    "\n",
    "# Get recommendations\n",
    "recommendations = recommend_lookalikes(user_input, df_customers)\n",
    "\n",
    "# Convert recommendations to a DataFrame and save to CSV\n",
    "df_recommendations = pd.DataFrame(recommendations)\n",
    "\n",
    "# Ensure the DataFrame is written to CSV\n",
    "df_recommendations.to_csv(\"Lookalike_Recommendations.csv\", index=False)\n",
    "\n",
    "# Show the recommendations and confirm the CSV output\n",
    "print(\"Recommendations:\")\n",
    "print(df_recommendations)\n",
    "\n",
    "# Confirm the CSV creation\n",
    "print(\"\\nCSV file 'Lookalike_Recommendations.csv' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "566356af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='Lookalike_Recommendations.csv' target='_blank'>Lookalike_Recommendations.csv</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\RD\\Downloads\\Lookalike_Recommendations.csv"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# Display download link for the CSV file\n",
    "FileLink(r'Lookalike_Recommendations.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0989799d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
